{"posts":[{"title":"window 安装mosquitto 2.0+","text":"安装windows版本 mosuqitto 2.0+并设置用户名密码 1.安装exe文件 2.找到安装位置，里面包含了mosquitto.exe，mosquitto_pw.exe 3.添加用户名密码 123# 这是注解，pwfile.example 当前文件，imyfit是用户名 .\\mosquitto_passwd.exe -c .\\pwfile.example imyfit # 点击enter，会让你输入两次密码，输入后就成功了 4.修改配置文件 1234#找到 listener 修改为 listener 1883 0.0.0.0 #找到 password_file 修改为 pwfile.example 文件的绝对路径 如：password_file D:/soft/mosquitto/pwfile.example 5.在任务管理器，服务里面找到mosquitto服务，重启测试","link":"/2024/03/23/window-%E5%AE%89%E8%A3%85mosquitto-2-0/"},{"title":"Spring Boot做出window服务","text":"将SpringBoot打包好的程序做成windows的服务，实现开机自启动 1.先下载WinSW-x64.exe，地址为：https://github.com/kohsuke/winsw/releases 2.将WinSW-x64.exe改成自己服务的名称如：test-engine.exe 3.在同级目录下新建一个名称相同的xml文件：test-engine.xmlxml的配置内容如下： 1234567891011121314151617181920&lt;!-- 这里的根元素必须是service节点 --&gt;&lt;service&gt; &lt;!-- 指定在Windows系统内部使用的识别服务的ID,唯一 --&gt; &lt;id&gt;test-engine&lt;/id&gt; &lt;!-- 服务的简短名称,唯一 --&gt; &lt;name&gt;test-engine&lt;/name&gt; &lt;!-- 描述 --&gt; &lt;description&gt;This is test engine service.&lt;/description&gt; &lt;!-- java环境变量 --&gt; &lt;env name=&quot;JAVA_HOME&quot; value=&quot;%JAVA_HOME%&quot;/&gt; &lt;!-- 指定要启动的可执行文件。 --&gt; &lt;executable&gt;java&lt;/executable&gt; &lt;!-- 指定要传递给可执行文件的参数,即：java -jar &quot;D:\\springboot-service\\demo-0.0.1-SNAPSHOT.jar&quot; --&gt; &lt;arguments&gt;-cp conf/;lib/* com.***.ImyFitEngineApplicationKt -- spring.config.location=conf/application.yml&lt;/arguments&gt; &lt;!-- 开机启动 --&gt; &lt;startmode&gt;Automatic&lt;/startmode&gt; &lt;!-- 日志配置 --&gt; &lt;logpath&gt;%BASE%\\log&lt;/logpath&gt; &lt;logmode&gt;rotate&lt;/logmode&gt;&lt;/service&gt; 注：修改配置文件xml的jvm参数，每次重启会自动使用该配置参数 4.注册服务，在黑框中运行，注册成功即可在服务中看到相关服务的名称，启动即可 1text-engine.exe install 5.注销服务 1test-engine.exe uninstall 6.停止服务 1test-engine.exe stop 7.重启服务 1test-engine.exe restart 8.查看服务状态 1test-engine.exe status","link":"/2022/02/01/Spring-Boot%E5%81%9A%E5%87%BAwindow%E6%9C%8D%E5%8A%A1/"},{"title":"windows程序开机自启动","text":"将自定义的exe或者bat文件程序，在windows下开机自启动 win+R 调出运行窗口 输入 shell:startup 按enter键 将要开机启动的程序快捷方式拖到弹出的文件夹中 12:: 如下路径C:\\Users\\用户名\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup","link":"/2022/02/02/windows%E7%A8%8B%E5%BA%8F%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8/"},{"title":"nginx解析动态域名","text":"nginx代理有时候存在着，根据域名动态解析处ip地址（即域名不变ip可能随着时间变化会改变的情况），使用ip地址代理接口，使用resolver 使用以下代理处理： 12345678910111213141516171819server { listen 80; server_name m200.test.com; #charset koi8-r; #access_log logs/host.access.log main; location / { autoindex on; autoindex_exact_size off; charset utf-8; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, PUT, POST, DELETE, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'Content-Type,*'; // 重点解析域名 resolver 114.114.114.114 valid=3s; set $test &quot;test.f3322.net:5001&quot;; proxy_pass http://${test}; }}","link":"/2021/03/01/nginx%E8%A7%A3%E6%9E%90%E5%8A%A8%E6%80%81%E5%9F%9F%E5%90%8D/"},{"title":"ubuntu相关指令","text":"ubuntu各种指令集集合 1.防火墙相关 12345678910111213141516# 查看防火墙状态sudo ufw status# 关闭防火墙sudo ufw disable# 开启防火墙sudo ufw enable# 外来访问默认允许/拒绝ufw default allow/deny# 允许/拒绝 访问20端口,20后可跟/tcp或/udp，表示tcp或udp封包。ufw allow/deny 20# ufw从/etc/services中找到对应service的端口，进行过滤。ufw allow/deny servicename# 允许自10.0.1.0/10的tcp封包访问本机的25端口。ufw allow proto tcp from 10.0.1.0/10 to 本机ip port 25# 删除以前定义的&quot;允许/拒绝访问20端口&quot;的规则ufw delete allow/deny 20 2.修改root密码 1sudo passwd root 3.更新数据源 1234567891011121314151617# 进入目录cd /etc/apt# 备份数据源cp sources.list sources.list.bak# 阿里数据源deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse# 更新数据源apt-get update 4.开发22端口 12apt-get install openssh-server openssh-clientservice ssh start 5.安装拉取上传文件指令 12# sz 文件名 将文件拉取到本地apt install lrzsz 6.状态栏点击软件放大缩小 1gsettings set org.gnome.shell.extensions.dash-to-dock click-action 'minimize' 7.连接远程lunix服务器 12345678910111213141516ssh root@ip地址#root@ip地址 password: 要登录服务器的账户的密码# 退出exit# 原创传输文件scp 文件 root@ip地址:/home/cositea/(文件路径)# 如果你反过来操作，把远程主机的文件拷贝到当前系统，操作命令以下；scp root@223.6.6.6:/renwole123/mariadb.tar.gz /renwole# 如果你想拷贝文件夹以及文件夹内的所有文件,就加参数 -r 如果你的端口号不是22，# 那么需要在scp后加个 -P (区分大小写)端口号。# 建议加-C选项，因为这样可以启用SSH的压缩功能；传输速度更快，例如scp -P 6632 -C /renwole/mariadb root@223.6.6.6:/renwole123/ 8.连接远程windows服务器 12345678910111213141516sudo apt-get install rdesktop# 访问服务器系统rdesktop 192.168.0.3# -u xxxxxx 登录用户，可选# -p xxxxxx 登录密码，可选 # -r clipboard:PRIMARYCLIPBOARD 重要，剪贴板可以与远程桌面交互 # -a 16 颜色，可选，不过最高就是16 位 # -z 压缩，可选 # -g 1024x768 分辨率，可选，缺省是一种比当前本地桌面低的分辨率 # -P 缓冲，可选 # -r disk:wj=/home/magicgod 映射虚拟盘，可选，# 会在远程机器的网上邻居里虚拟出一个映射盘，功能很强，甚至可以是软盘或光盘# -r sound:off 关闭声音，当然也可以把远程发的声音映射到本地来# 虚拟机就不要用这个了，用了就是悲剧，最好调整虚拟机这个切换快捷键# rdesktop退出全屏模式 ：使用组合键ctrl+alt+enter进行切换。 9.snap安装相关 1234567891011121314151617181920212223# 查看电脑上安装的软件snap list# 在软件商城发现软件snap find &lt;软件包名&gt;# 安装nap install &lt;snap软件包名&gt;# 更新snap refresh &lt;snap软件包名&gt;# 更新所有snap refresh all# 还原到以前安装snap revert &lt;snap软件包名&gt;# 卸载软件snap remove &lt;snap软件包名&gt;# 安装固定版本软件# 查看信息snap info mosquitto# 安装snap install mosquitto --channel=1.3/stable# 配置文件nano /etc/mosquitto/mosquitto.conf 10.开机自启动脚本 1234567891011121314#1.首先编写一个脚本vim auto_start#2.编写执行的内容#!/bin/bash/usr/lib/vino/vino-server#3.赋权限sudo chmod 777 auto_start#4.移动到 /etc/init.dsudo mv auto_start /etc/init.d#5.添加开机启动# update-rc.d ＜serviceName＞ defaults NN # NN是一个决定启动顺序的两位数字值sudo update-rc.d auto_start defaults 90#6.删除开机启动sudo update-rc.d -f auto_start remove","link":"/2021/02/23/ubuntu%E7%9B%B8%E5%85%B3%E6%8C%87%E4%BB%A4/"},{"title":"String拆分字符串","text":"String类的split()的方法使用： // 传入正则表达式 public String[] split(String regex) // 传入正则表达式、返回数组限制长度 public String[] split(String regex, int limit) 1.简单点的按.切分 1234567public class TestString { public static void main(String[] args) { String str = &quot;nihao.a&quot;; String[] split = str.split(&quot;.&quot;); System.out.println(Arrays.toString(split)); }} 输出结果 1[] 注：类似于.这样的英文特殊符号，因为正则的关系，达不到想要的结果，需要做如下处理： 1String[] split = str.split(&quot;\\\\.&quot;); 输出结果 1[nihao, a] 以下方式也输出同样的效果 1String[] split = str.split(&quot;[.]&quot;); 注：类似的特殊英文字符包含，都可以使用以上方式解决（[,]只能使用\\\\方式）如下 1\\ ^ $ ? * + ( ) [ ] { } 2.使用split带限制数组长度 1234567public class TestString { public static void main(String[] args) { String str = &quot;nihao.a&quot;; String[] split = str.split(&quot;\\\\.&quot;,1); System.out.println(Arrays.toString(split)); }} 输出结果 1[nihao.a] 注：因为限制了一个，如果数组只能长度为1，观看源码，会发现到限制的limit-1的时候就调用subString方法，直接截取后端了，核心代码如下： 12345678910if (!limited || list.size() &lt; limit - 1) { list.add(substring(off, next)); off = next + 1;} else { // last one //assert (list.size() == limit - 1); int last = length(); list.add(substring(off, last)); off = last; break;} 再看下一段代码： 1String[] split = str.split(&quot;\\\\.&quot;,4); 输出结果 1[nihao, a] 会发现没有输出4个长度的数组，只输出两个，主要是他只能拆分成长度为2的数组，再看下一个例子，就能看出来limit的作用了 1234567public class TestString { public static void main(String[] args) { String str = &quot;nihao.aaa&quot;; String[] split = str.split(&quot;a&quot;); System.out.println(Arrays.toString(split)); }} 输出结果 1[nih, o.] 对比一下加上limit的结果 1String[] split = str.split(&quot;a&quot;, 6); 可以猜测一下，按照正常情况，加上后面3个a，理论上应该输出长度为5的数组 1[&quot;nih&quot;,&quot; o.&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;] 预测的一样，是长度为5的情况，怎么会这样的呢，limit的左右是什么，查看源码，重点片段 1234567if (limit == 0) { while (resultSize &gt; 0 &amp;&amp; list.get(resultSize - 1).isEmpty()) { resultSize--; }}String[] result = new String[resultSize];return list.subList(0, resultSize).toArray(result); 当limit为0的时候，会去掉为空的数组元素，但是加了limit就不会","link":"/2025/03/24/String%E6%8B%86%E5%88%86%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"title":"当面试官说“你还有什么问题想要问的”，如何回答？","text":"当面试官说“你还有什么问题想要问的”，如何回答？ 很多面试结束，不管成功与否，面试官都会抛出一句，“你还有什么问题想问的”，不能面试随口一问，你千万不能随口一答，想好你最关心的问题，这也是你了解公司、展现自我的最好机会，千万别浪费。 所以，面试前要对公司足够的了解，便于最后一问问出特色，给面试官留下深刻的印象。 越来越多的面试官把“你还有什么问题想问我”当做最后一道面试题，考察求职者关注什么，借以了解他的求职动机，还能判断他的性格、格局、价值观。 有的求职者问的是关于薪酬福利、加班、休假的问题，可以看出他很在意眼前的个人利益；有的求职者问的是公司发展前景，岗位上升空间，可以看出他比较有上进心。 谁都喜欢一个积极上进，而不是上来就谈报酬、对个人利益看得很重的求职者。 此类问题大致分为三种情形：部门负责人面、HR面、高层领导面。针对不同的人咨询不同的问题。 一、部门负责人面 此时，你可以选择问： 1.借着这个机会，深入的了解你要面试岗位的一些具体要求。 2.具体了解一下，面试岗位未来的发展状况是什么样的。 3.公司和部门的组织架构是怎么安排的？ 等等职业相关，技术，岗位相关的，坚决不要问薪资相关，这是HR谈的事情 二、HR面1.面试岗位的薪资构成是怎样的呢？ 2.请问贵公司在待遇福利方面有哪些呢？ 3.如果顺利入职的话，请问我的试用期是多久？是否有提前转正的机会？ 4.请问贵公司的上下班时间是怎样的？周末的双休和法定节假日是怎样的机制呢？ 5.请问这个部门的人员流动性怎么样呢？ 如果你已进入到和HR谈薪的阶段，那说明你已经基本符合了该公司该岗位的招聘要求，与HR的有效沟通是很重要的，要把握住哦，直通终面不是梦！ 三、高层领导面 1.刚问所在团队当下的重点工作是什么呢？ 2.可以问一下晋升相关的事情？ 3.问问公司整体规划是什么情况？","link":"/2025/03/20/%E9%9D%A2%E8%AF%951/"},{"title":"并发相关","text":"1.线程有几种状态Java种，线程池有六种状态： 状态 描述 初始（NEW） 新创建了一个线程对象，但是还没有调用start()方法 运行（RUNNABLE） Java线程将操作系统中的就绪和运⾏两种状态笼统的称作“运⾏” 阻塞（BLOCKED） 表示线程阻塞于锁 等待（WAITING） 进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断） 超时等待（TIMED_WAITING） 该状态不同于 WA IT IND，它是可以在指定的时间⾃⾏返回 终止（TERMINATED） 表示当前线程已经执行完毕 线程状态图 线程涉及的几种方法 线程等待方法 obj.wait():当⼀个线程A调⽤⼀个共享变量的 wait()⽅法时,线程A会被阻塞挂起,发⽣下⾯⼏种情况才会返回 ： ​ 线程A调⽤了共享对象 notify()或者 notifyAll()⽅法； ​ 其他线程调⽤了线程A的 interrupt() ⽅法，线程A抛出InterruptedException异常返回 obj.wait(long timeout)/obj.wait(long millis, int nanos): timeout时间到了自动唤醒。 thread.join()/thread.join(long millis)/thread.join(long millis, int nanos)，当前线程里调用其它线程t的join方法，当前线程进入WAITING/TIMED_WAITING状态，当前线程不会释放已经持有的对象锁。线程t执行完毕或者millis时间到，当前线程一般情况下进入RUNNABLE状态，也有可能进入BLOCKED状态（因为join是基于wait实现的） 线程通知 obj.notify(): ⼀个线程A调⽤共享对象的 notify() ⽅法后，会唤醒⼀个在这个共享变量上调⽤ wait系列⽅法后被挂起的线程。 ⼀个共享变量上可能会有多个线程在等待，具体唤醒哪个等待的线程是随机的。 obj.notifyAll()：不同于在共享变量上调⽤ notify() 函数会唤醒被阻塞到该共享变量上的⼀个线程，notifyAll() ⽅法则会唤醒所有在该共享变量上由于调⽤ wait 系列⽅法⽽被挂起的线程 线程让出优先权 Thread.yield()：一定是当前线程调用此方法，当前线程放弃获取的CPU时间片，但不释放锁资源，由运行状态变为就绪状态，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield()不会导致阻塞。该方法与sleep()类似，只是不能由用户指定暂停多长时间。 线程终端 Java 中的线程中断是⼀种线程间的协作模式，通过设置线程的中断标志并不能直接终⽌该线程的执 ⾏，⽽是被中断的线程根据中断状态⾃⾏处理。 void interrupt() ：中断线程，例如，当线程A运⾏时，线程B可以调⽤线程interrupt() ⽅法来设置线程的中断标志为true 并⽴即返回。设置标志仅仅是设置标志, 线程A实际并没有被中断， 会继续往下执⾏。 boolean isInterrupted() ⽅法： 检测当前线程是否被中断。 boolean interrupted() ⽅法： 检测当前线程是否被中断，与 isInterrupted 不同的是，该⽅法如果发现当前线程被中断，则会清除中断标志。 线程休眠 Thread.sleep(long millis)：一定是当前线程调用此方法，当前线程进入TIMED_WAITING状态，但不释放对象锁，millis后线程自动苏醒进入就绪状态。作用：给其它线程执行机会的最佳方式。","link":"/2025/03/27/%E5%B9%B6%E5%8F%91/"},{"title":"JMM(Java内存模型)","text":"Java 内存模型（JMM）定义了 Java 程序中的变量、线程如何和主存以及工作内存进行交互的规则。它主要涉及到多线程环境下的共享变量可见性、指令重排等问题，是理解并发编程中的关键概念。 Java 内存模型（JMM）主要针对的是多线程环境下，如何在主内存与工作内存之间安全地执行操作。 什么是JMM？JMM全称（Java Memory Model）Java内存模型，可以看作是Java定义的并发编程相关的一组规范，除了抽象了线程和主内存之间的关系之外，其还规定了从Java源代码到CPU可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性。 为什么要遵守这些并发相关的原则和规范呢？ 这是因为并发编程下，像 CPU 多级缓存和指令重排这类设计可能会导致程序运行出现一些问题。就比如说我们上面提到的指令重排序就可能会让多线程程序的执行出现问题，为此，JMM 抽象了 happens-before 原则来解决这个指令重排序问题。 JMM 说白了就是定义了一些规范来解决这些问题，开发者可以利用这些规范更方便地开发多线程程序。对于 Java 开发者说，你不需要了解底层原理，直接使用并发相关的一些关键字和类（比如 volatile、synchronized、各种 Lock）即可开发出并发安全的程序。 JMM 与 Java 运行时内存区域的区别前面提到了 JMM 和 Java 运行时内存区域的划分，这两者既有差别又有联系： 区别 两者是不同的概念。JMM 是抽象的，他是用来描述一组规则，通过这个规则来控制各个变量的访问方式，围绕原子性、有序性、可见性等展开。而 Java 运行时内存的划分是具体的，是 JVM 运行 Java 程序时必要的内存划分。 联系 都存在私有数据区域和共享数据区域。一般来说，JMM 中的主存属于共享数据区域，包含了堆和方法区；同样，JMM 中的本地内存属于私有数据区域，包含了程序计数器、本地方法栈、虚拟机栈。 总结一下： Java 运行时内存区域描述的是在 JVM 运行时，如何将内存划分为不同的区域，并且每个区域的功能和工作机制。主要包括以下几个部分： 方法区（1.8之前）：存储了每一个类的结构信息，如运行时常量池、字段和方法数据、构造方法和普通方法的字节码内容。 元空间（1.8之后）：类的元信息被存储在元空间中。元空间没有使用堆内存，而是与堆不相连的本地内存区域，直接内存。所以，理论上系统可以使用的内存有多大，元空间就有多大，所以不会出现永久代存在时的内存溢出问题。 可以通过 -XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 来指定元空间的大小。 堆：几乎所有的对象实例以及数组都在这里分配内存。这是 Java 内存管理的主要区域。 栈：每一个线程有一个私有的栈，每一次方法调用都会创建一个新的栈帧，用于存储局部变量、操作数栈、动态链接、方法出口等信息。所有的栈帧都是在方法调用和方法执行完成之后创建和销毁的。 本地方法栈：与栈类似，不过本地方法栈为 JVM 使用到的 native 方法服务。 程序计数器：每个线程都有一个独立的程序计数器，用于指示当前线程执行到了字节码的哪一行。 Java 内存模型 (JMM) 主要针对的是多线程环境下，如何在主内存与工作内存之间安全地执行操作。 线程之间的共享变量存在于主存中，每个线程都有一个私有的本地内存，存储了该线程的读、写共享变量的副本。本地内存是 Java 内存模型的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器等。 happens-before 关系的定义如下： 如果一个操作 happens-before 另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 两个操作之间存在 happens-before 关系，并不意味着 Java 平台的具体实现必须要按照 happens-before 关系指定的顺序来执行。如果重排序之后的执行结果，与按 happens-before 关系来执行的结果一致，那么 JMM 也允许这样的重排序。 happens-before 关系本质上和 as-if-serial 语义是一回事。 as-if-serial 语义保证单线程内重排序后的执行结果和程序代码本身应有的结果是一致的，happens-before 关系保证正确同步的多线程程序的执行结果不被重排序改变。 总之*如果操作 A happens-before 操作 B，那么操作 A 在内存上所做的操作对操作 B 都是可见的，不管它们在不在一个线程 happens-before-常见规则有哪些?happens-before 的规则就 8 条，说多不多，重点了解下面列举的 5 条即可。全记是不可能的，很快就忘记了，意义不大，随时查阅即可。 程序顺序规则：一个线程内，按照代码顺序，书写在前面的操作 happens-before 于书写在后面的操作； 解锁规则：解锁 happens-before 于加锁； volatile 变量规则：对一个 volatile 变量的写操作 happens-before 于后面对这个 volatile 变量的读操作。说白了就是对 volatile 变量的写操作的结果对于发生于其后的任何操作都是可见的。 传递规则：如果 A happens-before B，且 B happens-before C，那么 A happens-before C； 线程启动规则：Thread 对象的 start()方法 happens-before 于此线程的每一个动作 再看并发编程三个重要特性原子性 一次操作或者多次操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么都不执行。 在 Java 中，可以借助synchronized、各种 Lock 以及各种原子类实现原子性。 synchronized 和各种 Lock 可以保证任一时刻只有一个线程访问该代码块，因此可以保障原子性。各种原子类是利用 CAS (compare and swap) 操作（可能也会用到 volatile或者final关键字）来保证原子操作。 可见性 当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。 在 Java 中，可以借助synchronized、volatile 以及各种 Lock 实现可见性。 如果我们将变量声明为 volatile ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。 有序性 由于指令重排序问题，代码的执行顺序未必就是编写代码时候的顺序。 我们上面讲重排序的时候也提到过： 指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致 ，所以在多线程下，指令重排序可能会导致一些问题。 在 Java 中，volatile 关键字可以禁止指令进行重排序优化。","link":"/2025/03/25/JMM-Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"title":"线程池","text":"什么是线程池？就是一个管理线程的池子，避免开发人员频繁的创建和销毁线程的资源耗损。 线程池核心参数corePoolSize：核心线程数 此值是⽤来初始化线程池中核⼼线程数，当线程池中线程池数&lt; corePoolSize 时，系统默认是添加⼀个任务才创建⼀个线程池。当线程数 = corePoolSize时，新任务会追加到workQueue中。 maximumPoolSize：最大线程数 maximumPoolSize 表⽰允许的最⼤线程数 = (⾮核⼼线程数+核⼼线程数)，当 BlockingQueue 也满了，但线程池中总线程数 &lt; maximumPoolSize 时候就会再次创建新的线程。 keepAliveTime：非核心线程存活实际 ⾮核⼼线程 =(maximumPoolSize - corePoolSize ) ,⾮核⼼线程闲置下来不⼲活最多存活时间。 unit：非核心线程存活时间单位 线程池中⾮核⼼线程保持存活的时间的单位 TimeUnit.DAYS: 天 TimeUnit.HOURS: ⼩时 TimeUnit.MINUTES: 分钟 TimeUnit.SECONDS: 秒 TimeUnit.MILLISECONDS: 毫秒 TimeUnit.MICROSECONDS: 微秒 TimeUnit.NANOSECONDS: 纳秒 workQueue：等待队列 线程池等待队列，维护着等待执⾏的 Runnable 对象。当运⾏当线程数= corePoolSize时，新的任务会被添加到 workQueue 中，如果 workQueue 也满了则尝试⽤⾮核⼼线程执⾏任务，等待队列应该尽量⽤有界的。 ArrayBlockingQueue：ArrayBlockingQueue（有界队列）是⼀个⽤数组实现的有界阻塞队列，按FIFO排序量。 LinkedBlockingQueue：LinkedBlockingQueue（可设置容量队列）是基于链表结构的阻塞队列，按FIFO排序任务，容量可以选择进⾏设置，不设置的话，将是⼀个⽆边界的阻塞队列，最⼤长度为Integer.MAX_VALUE，吞吐量通常要⾼于ArrayBlockingQuene；newFixedThreadPool线程池使⽤了这个队列 DelayQueue：DelayQueue（延迟队列）是⼀个任务定时周期的延迟执⾏的队列。根据指定的执⾏时间从⼩到⼤排序，否则根据插⼊到队列的先后排序。newScheduledThreadPool线程池使⽤了这个队列。 PriorityBlockingQueue：PriorityBlockingQueue（优先级队列）是具有优先级的⽆界阻塞队列 SynchronousQueue：SynchronousQueue（同步队列）是⼀个不存储元素的阻塞队列，每个插⼊操作必须等到另⼀个线程调⽤移除操作，否则插⼊操作⼀直处于阻塞状态，吞吐量通常要⾼于LinkedBlockingQuene，newCachedThreadPool线程池使⽤了这个队列。 threadFactory：创建线程使用工厂 创建⼀个新线程时使⽤的⼯⼚，可以⽤来设定线程名、是否为daemon线程等等。 handler：饱和拒绝策略 corePoolSize 、 workQueue 、 maximumPoolSize 都不可⽤的时候执⾏的饱和策略。 AbortPolicy ：直接抛出异常，默认使⽤此策略 CallerRunsPolicy：⽤调⽤者所在的线程来执⾏任务 DiscardOldestPolicy：丢弃阻塞队列⾥最⽼的任务，也就是队列⾥靠前的任务 DiscardPolicy ：当前任务直接丢弃 线程池的几种状态线程池有这⼏个状态：RUNNING,SHUTDOWN,STOP,TIDYING,TERMINATED。 RUNNING 该状态的线程池会接收新任务，并处理阻塞队列中的任务; 调⽤线程池的shutdown()⽅法，可以切换到SHUTDOWN状态; 调⽤线程池的shutdownNow()⽅法，可以切换到STOP状态; SHUTDOWN 该状态的线程池不会接收新任务； 队列为空，并且线程池中执⾏的任务也为空,进⼊TIDYING状态; 会继续执行正在跑的任务和处理阻塞队列中的任务，会执行完任务； STOP 该状态的线程不会接收新任务； 忽略掉阻塞队列中的任务，⽽且会中断正在运⾏的任务； 线程池中执⾏的任务为空,进⼊TIDYING状态; TIDYING 该状态表明所有的任务已经运⾏终⽌，记录的任务数量为0。 terminated()执⾏完毕，进⼊TERMINATED状态 TERMINATED 该状态表⽰线程池彻底终⽌ 自带的四种线程池建议自己手动创建线程池 newFixedThreadPool：固定数⽬线程的线程池 12345public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); } 线程池特点 核⼼线程数和最⼤线程数相等 阻塞队列是⽆界队列LinkedBlockingQueue，可能会导致OOM keepAliveTime为0 适⽤场景：适⽤于处理CPU密集型的任务，确保CPU在长期被⼯作线程使⽤的情况下，尽可能的少的分配线程，即适⽤执⾏长期的任务。 newCachedThreadPool：可缓存线程的线程池 12345public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); } 线程池特点 核⼼线程数为0 最⼤线程数为Integer.MAX_VALUE，即⽆限⼤，可能会因为⽆限创建线程，导致OOM 阻塞队列是SynchronousQueue keepAliveTime为60s 适用场景：用于并发执行大量短期的小任务 newSingleThreadExecutor ：单线程的线程池 123456public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); } 线程池特点 核⼼线程数和最⼤线程数也都为1 阻塞队列是⽆界队列LinkedBlockingQueue，可能会导致OOM keepAliveTime为0 适⽤场景：适⽤于串⾏执⾏任务的场景，⼀个任务⼀个任务地执⾏。 newScheduledThreadPool ：定时及周期执⾏的线程池 12345public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS, new DelayedWorkQueue());} 线程池特点 最⼤线程数为Integer.MAX_VALUE，也有OOM的风险 阻塞队列是DelayedWorkQueue keepAliveTime为10微秒 使⽤场景：周期性执⾏任务的场景，需要限制线程数量的场景","link":"/2025/03/28/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"title":"OOP原则","text":"面向对象编程（OOP）三大特性、五项原则 三大特性：封装、继承、多态封装将数据和方法隐藏在类中 封装的好处： 隐藏内部实现，保护数据安全。 提供统一的接口访问数据，提高代码可维护性。 继承 子类复用父类的属性与方法 继承的优点： 子类复用父类代码，减少冗余。 支持功能扩展，保持结构清晰。 多态 同一接口，不同表现形式 多态的核心： 统一接口，执行不同对象的行为。 提高代码的灵活性和可扩展性。 五大基本原则单一职责原则（SRP） 一个类功能要单一，只实现一个功能，控制类的粒度大小，将对象解耦，提高其内聚性 开放封闭原则（OCP） 对象或实体应该对扩展开放，对修改封闭。 更改封闭即是在我们对模块进行扩展时，勿需对源有程序代码和DLL进行修改或重新编译文件！这个原则对我们在设计类的时候很有帮助，坚持这个原则就必须尽量考虑接口封装，抽象机制和多态技术！ 里氏替换原则（LSP） 子类可以替换父类并且出现在父类能够出现的任何地方，这个原则也是在贯彻GOF倡导的面向接口编程！ 在这个原则中父类应该尽量使用抽象类和接口 依赖倒置原则（DIP） 要面向接口编程，不要面向实现编程 高层的模块不要依赖于低层的模块，抽象不依赖细节，细节应该依赖抽象； 面向接口编程，降低程序的耦合性。因为具体的实现具有多变性，但是接口一般来说都是稳定的（持久层）。 接口隔离原则（ISP） 要为各个类建立它们需要的专用接口 不应强迫客户端实现一个它用不上的接口，或是说客户端不应该被迫依赖它们不使用的方法，使用多个专门的接口比使用单个接口要好的多！","link":"/2025/03/28/OOP%E5%8E%9F%E5%88%99/"},{"title":"synchronized和ReentrantLock的区别","text":"项目中，常用的锁有两种：synchronized和ReentrantLock。 锁的实现synchronized是Java语言关键字，基于JVM实现。 ReentrantLock是基于JDK的API层面AQS实现。 用法synchronized 可以用来修饰普通方法、静态方法和代码块 ReentrantLock 只能用于代码块（使用lock()和unlock()方法，配合try/finally实现加锁释放锁） 性能在JDK1.6锁优化以前，synchronized的性能⽐ReenTrantLock差很多。但是JDK6开始，增加了适应性⾃旋、锁消除等，两者性能就差不多了。 锁类型不同synchronized 是非公平锁 ReentrantLock 默认为非公平锁，也可以手动指定为公平锁 中断synchronized不能响应中断 ReentrantLock提供了⼀种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制 1234567891011121314151617181920212223242526272829303132333435363738public class Test { static ReentrantLock lock = new ReentrantLock(); public static void main(String[] args) throws InterruptedException { Thread thread = new Thread(() -&gt; { try { lock.lockInterruptibly(); System.out.println(&quot;等待进入1&quot;); // 模仿工作 TimeUnit.SECONDS.sleep(3); System.out.println(&quot;开始工作1&quot;); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } }, &quot;thread&quot;); Thread thread2 = new Thread(() -&gt; { try { lock.lock(); System.out.println(&quot;等待进入2&quot;); // 模仿工作 TimeUnit.SECONDS.sleep(3); System.out.println(&quot;开始工作2&quot;); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } }, &quot;thread2&quot;); thread.start(); thread2.start(); TimeUnit.SECONDS.sleep(1); System.out.println(&quot;停留一段时间&quot;); // 终端线程 thread.interrupt(); }} 结果输出 12345678910等待进入1停留一段时间等待进入2java.lang.InterruptedException: sleep interrupted at java.base/java.lang.Thread.sleep(Native Method) at java.base/java.lang.Thread.sleep(Thread.java:337) at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446) at com.shudj.od.Test.lambda$main$0(Test.java:22) at java.base/java.lang.Thread.run(Thread.java:833)开始工作2 注：中断线程1，线程2就直接获取到锁，开始执行任务 等待/通知机制synchronized与wait()和notify()/notifyAll()⽅法结合实现等待/通知机制， ReentrantLock类借助Condition接⼜与newCondition()⽅法实现等待(await相关方法）/通知机制（signal、signalAll方法） 1234567891011121314151617181920212223242526272829303132333435363738394041public class Test { static ReentrantLock lock = new ReentrantLock(); static Condition condition = lock.newCondition(); public static void main(String[] args) throws InterruptedException { Thread thread = new Thread(() -&gt; { try { lock.lockInterruptibly(); System.out.println(new Date() + &quot;等待进入1&quot;); // 等待 condition.await(5, TimeUnit.SECONDS); System.out.println(new Date() + &quot;开始工作1&quot;); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } }, &quot;thread&quot;); thread.start(); TimeUnit.MILLISECONDS.sleep(100); lock.lock(); System.out.println(new Date() + &quot;停留一段时间&quot;); for (int i = 0; i &lt; 5; i++) { int finalI = i; new Thread(() -&gt; { try { System.out.println(new Date() + &quot;等待进入 =&gt;&quot; + finalI + &quot;进入阻塞队列&quot;); lock.lock(); System.out.println(new Date() + &quot;开始工作 =&gt;&quot; + finalI + &quot;拿到锁开始工作&quot;); TimeUnit.SECONDS.sleep(2); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } }, &quot;thread&quot;).start(); } TimeUnit.MILLISECONDS.sleep(100); lock.unlock(); }} 输出结果 123456789101112131415Fri Mar 28 18:25:36 CST 2025等待进入1Fri Mar 28 18:25:36 CST 2025停留一段时间Fri Mar 28 18:25:36 CST 2025等待进入 =&gt;1进入阻塞队列Fri Mar 28 18:25:36 CST 2025等待进入 =&gt;3进入阻塞队列Fri Mar 28 18:25:36 CST 2025等待进入 =&gt;0进入阻塞队列Fri Mar 28 18:25:36 CST 2025等待进入 =&gt;2进入阻塞队列Fri Mar 28 18:25:36 CST 2025等待进入 =&gt;4进入阻塞队列Fri Mar 28 18:25:36 CST 2025开始工作 =&gt;1拿到锁开始工作Fri Mar 28 18:25:38 CST 2025开始工作 =&gt;3拿到锁开始工作Fri Mar 28 18:25:40 CST 2025开始工作 =&gt;0拿到锁开始工作Fri Mar 28 18:25:42 CST 2025开始工作 =&gt;2拿到锁开始工作Fri Mar 28 18:25:44 CST 2025开始工作 =&gt;4拿到锁开始工作Fri Mar 28 18:25:46 CST 2025开始工作1Process finished with exit code 0 注：从开始开工作的输出，也能看出默认是非公平锁 voltatitle相⽐synchronized的加锁⽅式来解决共享变量的内存可见性问题，volatile就是更轻量的选择，它没有上下⽂切换的额外开销成本。 volatile可以确保对某个变量的更新对其他线程马上可见，⼀个变量被声明为volatile 时，线程在写⼊变量时不会把值缓存在寄存器或者其他地⽅，⽽是会把值刷新回主内存当其它线程读取该共享变量，会从主内存重新获取最新值，⽽不是使⽤当前线程的本地内存中的值。 volatitle可以保证线程可见且提供了一定的有序性，但是无法保证原子性。在JMM底层volatile是采用“内存屏障”来实现的，内存屏障会提供3个功能： 1.确保指令重排序不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面 2.会强制将缓存的修改操作立即写入主内存 3.写操作，会导致其他CPU的对应的缓存行无效","link":"/2025/03/28/synchronized-ReentrantLock/"},{"title":"MySQL索引相关","text":"索引是对数据库表中一列或多列的值进行排序的一种数据结构。MySQL索引的简历对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。 索引分类基本使用主键索引：InnoDB 主键是默认的索引，数据列不允许重复，不允许为 NULL，⼀个表只能有⼀个主键。 唯一索引：数据列不允许重复，允许为 NULL 值，一张表可有多个唯一索引，索引列的值必须唯一。如果是组合索引，则列值的组合必须唯一。 普通索引：一张表可以创建多个普通索引，一个普通索引可以包含多个字段，允许数据重复，允许 NULL 值插入。 组合索引：多列值组成⼀个索引，⽤于组合搜索，效率⼤于索引合并。 全文索引：它查找的是文本中的关键词，主要用于全文检索。 单例索引：一个索引只包含一个列，一个表可以有多个单例索引。 物理分类聚簇索引：聚簇索引（clustered index）不是单独的一种索引类型，而是一种数据存储方式。这种存储方式是依靠B+树来实现的，根据表的主键构造一棵B+树且B+树叶子节点存放的都是表的行记录数据时，方可称该主键索引为聚簇索引。聚簇索引也可理解为将数据存储与索引放到了一块，找到索引也就找到了数据。 非聚簇索引：数据和索引是分开的，B+树叶子节点存放的不是数据表的行记录。 1MyISAM 采⽤的是⾮聚簇索引，InnoDB 采⽤的是聚簇索引。 两种索引区别： 索引的数据结构是树，聚簇索引的索引和数据存储在⼀棵树上，树的叶⼦节点就是数据，⾮聚簇索引索引和数据不在⼀棵树上。 ⼀个表中只能拥有⼀个聚簇索引，⽽⾮聚簇索引⼀个表可以存在多个。 聚簇索引，索引中键值的逻辑顺序决定了表中相应⾏的物理顺序；索引，索引中索引的逻辑顺序与磁盘上⾏的物理存储顺序不同。 聚簇索引：物理存储按照索引排序；⾮聚集索引：物理存储不按照索引排序 数据结构B-树（B树）索引：多路搜索树，树高一层意味着多一次的磁盘I/O 关键字集合分布在整颗树中； 任何一个关键字出现且只出现在一个结点中； 搜索有可能在非叶子结点结束； 其搜索性能等价于在关键字全集内做一次二分查找； 自动层次控制； B+树索引 所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的； 不可能在非叶子结点命中； 非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层； 每一个叶子节点都包含指向下一个叶子节点的指针，从而方便叶子节点的范围遍历。 更适合文件索引系统； Hash索引：哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。 Hash索引仅仅能满足”=”,“IN”和”&lt;=&gt;”查询，不能使用范围查询。也不支持任何范围查询。 由于Hash索引比较的是进行Hash运算之后的Hash值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的Hash算法处理之后的Hash值的大小关系，并不能保证和Hash运算前完全一样。 索引失效场景 查询条件包含or，可能导致索引失效，只有当or条件同时都是主键的时候，索引才会生效； 如果字段类型是字符串，where 时⼀定⽤引号括起来，否则会因为隐式类型转换，索引失效； like 通配符可能导致索引失效，索键值以通配符%开头（如：like '%abc'），则索引失效，直接全表扫描；若只是以%结尾，则不影响索引构建； 联合索引，查询时的条件列不是联合索引中的第⼀个列，索引失效，即违背最左匹配原则； 在索引列上使⽤ mysql 的内置函数，索引失效； 对索引列运算（如，+、-、*、/），索引失效； 索引字段上使⽤（!= 或者 &lt;&gt;，not in，not like，not）时，可能会导致索引失效，普通索引使用 !=索引失效，主键索引没影响； 索引最多使用一个&gt;、&lt;的范围列，因此如果查询条件中有两个&gt;、&lt;范围列则无法全用到索引（在 InnoDB 的联合索引中，查询的时候只有匹配了前⼀个/左边的值之后，才能匹配下⼀个）； 索引字段上使⽤ is null， is not null，可能导致索引失效，只有允许为null的字段的索引，使用该关键字才会走索引； 左连接查询或者右连接查询查询关联的字段编码格式不⼀样，可能导致索引失效； MySQL 优化器估计使⽤全表扫描要⽐使⽤索引快,则不使⽤索引。 回表在 InnoDB 存储引擎⾥，利⽤辅助索引查询，先通过辅助索引找到主键索引的键值，再通过主键值查出主键索引⾥⾯没有符合要求的数据，它⽐基于主键索引的查询多扫描了⼀棵索引树，这个过程就叫回表。 覆盖索引在辅助索引⾥⾯，不管是单列索引还是联合索引，如果 select 的数据列只⽤辅助索引中就能够取得，不⽤去查主键索引，这时候使⽤的索引就叫做覆盖索引，避免了回表。","link":"/2025/03/30/MySQL%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%85%B3/"},{"title":"MySQL事物相关","text":"数据库中的事务是指对数据库执行一批操作，在同一个事务当中，这些操作最终要么全部执行成功，要么全部失败，不会存在部分成功的情况。 事务是一个原子操作。是一个最小执行单元。可以甶一个或多个SQL语句组成 在同一个事务当中所有的SQL语句都成功执行时，整个事务成功，有一个SQL语句执行失败，整个事务都执行失败。 事物四大特性原⼦性（Atomicity）：事务作为⼀个整体被执⾏，包含在其中的对数据库的操作要么全部被执⾏，要么都不执⾏。 ⼀致性（Consistency）：指在事务开始之前和事务结束以后，数据不会被破坏，假如 A 账户给 B 账户转 10 块钱，不管成功与否，A 和 B 的总⾦额是不变的。 隔离性（Isolation）：一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 读未提交：Read Uncommited RU 读未提交是隔离级别最低的一种事务级别。在这种隔离级别下，一个事务会读到另一个事务更新后但未提交的数据，如果另一个事务回滚，那么当前事务读到的数据就是脏数据，这就是脏读（Dirty Read）。 读已提交：Read Commited RC 在 Read Committed 隔离级别下，一个事务可能会遇到不可重复读（Non Repeatable Read）的问题。不可重复读是指，在一个事务内，多次读同一数据，在这个事务还没有结束时，如果另一个事务恰好修改了这个数据，那么，在第一个事务中，两次读取的数据就可能不一致。 可重复读：Repeatable Read RR 在Repeatable Read隔离级别下，一个事务可能会遇到幻读（Phantom Read）的问题。幻读是指，在一个事务中，第一次查询某条记录，发现没有，但是，当试图更新这条不存在的记录时，竟然能成功，并且，再次读取同一条记录，它就神奇地出现了。幻读就是没有读到的记录，以为不存在，但其实是可以更新成功的，并且，更新成功后，再次读取，就出现了。 串行化：Serializable Serializable 是最严格的隔离级别。在Serializable隔离级别下，所有事务按照次序依次执行，因此，脏读、不可重复读、幻读都不会出现。 虽然 Serializable 隔离级别下的事务具有最高的安全性，但是，由于事务是串行执行，所以效率会大大下降，应用程序的性能会急剧降低。如果没有特别重要的情景，一般都不会使用Serializable隔离级别。 持久性（Durability）：一个事务一旦提交，他对数据库中数据的改变就应该是永久性的。当事务提交之后，数据会持久化到硬盘，修改是永久性的。 MySQL的默认隔离界别是可重复读（RR）。 脏读、幻读、不可重复读 事务 A、B 交替执⾏，事务 A 读取到事务 B 未提交的数据，这就是脏读。 在⼀个事务范围内，两个相同的查询，读取同⼀条记录，却返回了不同的数据，这就是不可重复读。 事务 A 查询⼀个范围的结果集，另⼀个并发事务 B 往这个范围中插⼊ / 删除了数据，并静悄悄地提交，然后事务 A 再次查询相同的范围，两次读取得到的结果集不⼀样了，这就是幻读。 隔离级别 脏读可能性 不可重复读可能性 幻读可能性 读未提交 READ-UNCOMMITTED 有 有 有 读已提交 READ-COMMITTED 无 有 有 可重复读 REPEATABLE-READ 无 无 有 串行化 SERIALIZABLE 无 无 无 设置隔离级别 12# 隔离级别设置,READ-UNCOMMITTED读未提交,READ-COMMITTED读已提交,REPEATABLE-READ可重复读,SERIALIZABLE串行，my.initransaction-isolation=REPEATABLE-READ 重启MySQL服务，查看隔离界别 1show variables like 'transaction_isolation';","link":"/2025/03/30/MySQL%E4%BA%8B%E7%89%A9%E7%9B%B8%E5%85%B3/"},{"title":"List集合","text":"Java集合中常用的集合ArrayList，LinkedList 区别 数据结构不同 ArrayList集合主要基于数组实现 LinkedList是基于双向链表实现 查找时间复杂度用区别 ArrayList的get(int index)，是直接通过下标遍历获取，时间复杂度O(1) LinkedList的get(int index)，需要遍历链表获取，时间复杂度为O(n) 两个如果使用get(E element)，都是需要遍历，时间复杂度为O(n) 插入和删除数据区别 LinedList的插入和删除直接，修改前一个节点的和后一个节点的指向就好了（便利于增删） ArrayList的插入和删除比较复杂，如果是结尾插入直接插入就好，删除直接置null；如果需要插入add(int index, E element);中间的位置元素，需要把当前index的元素向后移动，中间可能涉及到扩容（一般按照1.5倍扩容，如果加入的元素大于1.5倍，按照添加元素的个数大于当前的一半，则按照添加元素个数扩容）；如果需要删除中间位置的元素，需要把当前index+1的元素向前移动，最后一位置null； 1234567891011121314// 扩容算法private Object[] grow(int minCapacity) { int oldCapacity = elementData.length; if (oldCapacity &gt; 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { // 返回扩容后的长度 int newCapacity = ArraysSupport.newLength(oldCapacity, minCapacity - oldCapacity, /* minimum growth */ oldCapacity &gt;&gt; 1 /* preferred growth */); // 复制当前数组到扩容后的数组 return elementData = Arrays.copyOf(elementData, newCapacity); } else { return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)]; }} modCount属性12345678/*** 此列表在 结构上被修改的次数。结构修改是指更改列表大小的修改，或者以其他方式干扰列表，以至于正在进行的迭代可能会产生不正确的结* 果。此字段由 and listIterator 方法返回的iterator迭代器和列表迭代器实现使用。如果此字段的值意外更改，则迭代器（或列表迭代 * 器）将抛出 a ConcurrentModificationException 以响应 next、 remove、 previousset 或 add作。这提供了快速失败的行为，* 而不是在迭代期间面对并发修改时的非确定性行为。* 子类使用此字段是可选的。 如果子类希望提供快速失败的迭代器（和列表迭代器），那么它只需要在其 add(int, E) and remove(int) 方* 法（以及它覆盖的导致列表结构修改的任何其他方法）中增加此字段。对此字段的 add(int, E) 单个调用或 remove(int) 必须向此字段添* 加不超过一个，否则迭代器（和列表迭代器）将引发 bogus ConcurrentModificationExceptions。如果实现不希望提供 fail-fast 迭* 代器，则可以忽略此字段。**/protected transient int modCount = 0; ArrayList线程安全的方法 使用Vector代替 使用Collections.synchronizedList包装ArrayList，返回的是一个List，对所有的add，remove等操作都使用synchronized加了锁 12345public static &lt;T&gt; List&lt;T&gt; synchronizedList(List&lt;T&gt; list) { return (list instanceof RandomAccess ? new SynchronizedRandomAccessList&lt;&gt;(list) : new SynchronizedList&lt;&gt;(list));} 使用CopyOnWriteArrayList代替 CopyOnWriteArrayList采⽤了⼀种读写分离的并发策略。CopyOnWriteArrayList容器允许并发读，读操作是⽆锁的，性能较⾼。⾄于写操作，⽐如向容器中添加⼀个元素，则⾸先将当前容器复制⼀份，然后在新副本上执⾏写操作，结束之后再将原容器的引⽤指向新容器。","link":"/2025/04/10/List%E9%9B%86%E5%90%88/"},{"title":"MySQL锁相关","text":"锁（Locking）是数据库在并发访问时保证数据一致性和完整性的主要机制 锁的分类粒度分类 表锁：具有开销⼩，加锁快的特性；锁定⼒度⼤，发⽣锁冲突概率⾼，并发度最低；不会出现死锁。 ⾏锁：具有开销⼤，加锁慢的特性；锁定粒度⼩，发⽣锁冲突的概率低，并发度⾼；会出现死锁。 页锁：开销和加锁速度介于表锁和⾏锁之间；锁定粒度介于表锁和⾏锁之间，并发度⼀般；会出现死锁。 兼容性分类 共享锁(S Lock)，也叫读锁（read lock），允许获得该锁的事务读取数据行，同时允许其他事务获得该数据行上的共享锁，并且阻止其他事务获得数据行上的排他锁，相互不阻塞的。 获取共享锁 select ... for share，在MySQL8.0以后的版本 select ... lock in share mode，在MySQL8.0之前的版本 排他锁(X Lock)，也叫写锁（write lock），允许获得该锁的事务更新或删除数据行，排它锁是阻塞的，在⼀定时间内，只有⼀个请求能执⾏写⼊，并阻⽌其它锁读取正在写⼊的数据。 获取排他锁 select ... for update 两种锁的兼容性： 锁类型 共享锁 排他锁 共享锁 兼容 冲突 排他锁 冲突 冲突 意向锁分类意向锁是⼀个表级锁，不要和插⼊意向锁搞混。 意向锁的出现是为了⽀持 InnoDB 的多粒度锁，它解决的是表锁和⾏锁共存的问题。 当我们需要给⼀个表加表锁的时候，我们需要根据去判断表中有没有数据⾏被锁定，以确定是否能加成功。 假如没有意向锁，那么我们就得遍历表中所有数据⾏来判断有没有⾏锁；有了意向锁这个表级锁之后，则我们直接判断⼀次就知道表中是否有数据⾏被锁定了。有了意向锁之后，要执⾏的事务 A 在申请⾏锁（写锁）之前，数据库会⾃动先给事务 A 申请表的意向排他锁。当事务 B 去申请表的互斥锁时就会失败，因为表上有意向排他锁之后事务 B 申请表的互斥锁时会被阻塞。 意向锁属于表级锁，由 InnoDB 自动添加，不需要用户干预。意向锁也分为共享和排他两种方式： 意向共享锁(IS)：事务在给数据行加行级共享锁之前，必须先取得该表的 IS 锁。 意向排他锁(IX)：事务在给数据行加行级排他锁之前，必须先取得该表的 IX 锁。 锁类型 共享锁(S) 排他锁(X) 意向共享锁(IS) 意向排他锁(IX) 共享锁(S) 兼容 冲突 兼容 冲突 排他锁(S) 冲突 冲突 冲突 冲突 意向共享锁(IS) 兼容 冲突 兼容 兼容 意向排他锁(IX) 冲突 冲突 兼容 兼容 InnoDB ⾥的⾏锁实现InnoDB 通过给索引上的索引记录加锁的方式实现行级锁。具体来说，InnoDB 实现了三种行锁的算法：记录锁（Record Lock）、间隙锁（Gap Lock）和 Next-key 锁（Next-key Lock）又称临键锁。 其中间隙锁只在RR隔离级别下生效，其目的是为了防止产生幻读。Next-key 锁（Next-key Lock）相当于一个索引记录锁加上该记录之前的一个间隙锁。 间 隙 锁(Gap Locks) 和 临 键 锁(Next-Key Locks) 都是⽤来解决幻读问题的，在 已 提 交 读 （READ COMMITTED） 隔离级别下， 间 隙 锁(Gap Locks) 和 临 键 锁(Next-Key Locks) 都会失效！ 记录锁记录锁（Record Lock）是针对索引记录（index record）的锁定。例如，SELECT * FROM t WHERE id = 1 FOR UPDATE;会阻止其他事务对表 t 中 id = 1 的数据执行插入、更新，以及删除操作。 全局变量 innodb_status_output 和 innodb_status_output_locks 用于控制 InnoDB 标准监控和锁监控，我们利用监控查看锁的使用情况。 12set GLOBAL innodb_status_output = ON;set GlOBAL innodb_status_output_locks=ON; 使用SHOW ENGINE INNODB STATUS命令查看 InnoDB 监控中关于锁的事务数据。 间隙锁间隙锁（Gap Lock）锁定的是索引记录之间的间隙、第一个索引之前的间隙或者最后一个索引之后的间隙，是一个左开右开的空间。例如，SELECT * FROM t WHERE c1 BETWEEN 1 and 10 FOR UPDATE；会阻止其他事务将 1 到 10 之间的任何值插入到 c1 字段中，即使该列不存在这样的数据；因为这些值都会被锁定。 加锁规则有以下特性： 加锁的基本单位是（next-key lock）,他是前开后闭原则(这里实际是指的记录锁与间隙锁的组合) 插叙过程中访问的对象会增加锁 索引上的等值查询–给唯一索引加锁的时候，（next-key lock）升级为记录锁(注：在&gt;=或between时只对主键生效，唯一但非主键索引不生效)。 索引上的等值查询–向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁 唯一索引上的范围查询会访问到不满足条件的第一个值为止 Next-key 锁Next-key 锁（Next-key Lock）相当于一个索引记录锁加上该记录之前的一个间隙锁，是一个左开右闭的空间。 InnoDB 实现行级锁的方式如下：当搜索或扫描表索引时，在遇到的索引记录上设置共享锁或排它锁。因此，InnoDB 行级锁实际上是索引记录锁。 Insert Intention Lock插⼊意向锁⼀个事务在插⼊⼀条记录时需要判断⼀下插⼊位置是不是被别的事务加了意向锁 ，如果有的话，插⼊操作需要等待，直到拥有 gap 锁 的那个事务提交。但是事务在等待的时候也需要在内存中⽣成⼀个锁结构 ，表明有事务想在某个 间隙 中插⼊新记录，但是现在在等待。这种类型的锁命名为 Insert Intention Locks ，也就是插⼊意向锁 。 悲观锁和乐观锁悲观锁悲观锁认为被它保护的数据是极其不安全的，每时每刻都有可能被改动，⼀个事务拿到悲观锁后，其他任何事务都不能对该数据进⾏修改，只能等待锁被释放才可以执⾏。 数据库中的⾏锁，表锁，读锁，写锁均为悲观锁。 乐观锁我们通常用的字段version，业务代码控制判断，where 条件判断version是不是拿到的上一个值，如果是执行，如果不是说明有其他事务对该行数据做了更改，则当前事务执行失败。 死锁的预防和避免 尽早提交事务： 避免在事务中执行长时间的计算、网络操作或其他耗时操作，以减少锁的持有时间。 拆分大事务： 将大事务拆分为多个较小的事务，以减少事务的持有锁时间。 使用合适的索引： 确保查询语句使用合适的索引，以减少锁定的数据量。 使用索引可以提高查询效率，并减少事务持有锁的时间。 优化查询语句： 尽量使用更精确的条件来限制查询范围，避免长时间持有锁定的行。 使用乐观锁： 对于一些并发较高的场景，可以考虑使用乐观锁机制。 乐观锁不会持有实际的锁，而是通过版本号或时间戳等方式进行冲突检测，减少了事务持有锁的时间。 提高系统性能： 提升数据库服务器的性能，例如增加内存、优化硬件配置等，可以减少事务持有锁的时间。 确保系统具有足够的资源来处理并发请求，避免因资源不足而导致事务等待。","link":"/2025/04/11/MySQL%E9%94%81%E7%9B%B8%E5%85%B3/"},{"title":"Redis内存淘汰策略","text":"本文详细介绍了Redis的内存淘汰策略，包括定期删除和惰性删除，并讨论了为何需要两种策略。此外，还讲解了如何配置Redis的最大内存大小，以及提供了多种内存淘汰策略，如no-enviction、allkeys-random等。 Redis过期删除策略 惰性删除 惰性删除指的是当我们查询key的时候才对key进⾏检测，如果已经达到过期时间，则删除。显然，他有⼀个缺点就是如果这些过期的key没有被访问，那么他就⼀直⽆法被删除，⽽且⼀直占⽤内存。 定期删除 定期删除指的是Redis每隔⼀段时间对数据库做⼀次检查，删除⾥⾯的过期key。由于不可能对所有key去做轮询来删除，所以Redis会每次随机取⼀些key去做检查和删除。 配置内存 修改配置文件 redis.conf（一直有效） 1234567891011121314# Note on units: when memory size is needed, it is possible to specify# it in the usual form of 1k 5GB 4M and so forth:## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive so 1GB 1Gb 1gB are all the same.# 以下就是设置redis内存大小的地方# maxmemory &lt;bytes&gt; 通过客户端设置（重启服务失效） 1config set maxmemory 100mb Redis内存淘汰策略 noeviction 默认策略，不会删除任何数据，拒绝所有写⼊操作并返 回客户端错误信息，此时Redis只响应读操作。 volatile-lru 根据LRU（删除最近少用的）算法删除设置了超时属性（expire）的键，直到腾出⾜够空间为⽌。如果没有可删除的键对象，回退到noeviction策略。 allkeys-lru 根据LRU（删除最近少用的）算法删除键，不管数据有没有设置超时属性， 直到腾出⾜够空间为⽌。 allkeys-random 随机删除所有键，直到腾出⾜够空间为⽌。 volatile-random 随机删除过期键，直到腾出⾜够空间为⽌。 volatile-ttl 根据键值对象的ttl属性，删除最近将要过期数据。如果 没有，回退到noeviction策略。 volatile-lfu使用LFU（Least Frequently Used，最不经常使用），从设置了过期时间的键中选择某段时间之内使用频次最小的键值对清除掉 allkeys-lfu使用LFU（Least Frequently Used，最不经常使用），从所有的键中选择某段时间之内使用频次最少的键值对清除 123456789101112131415161718192021222324252627282930# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached. You can select one from the following behaviors:## volatile-lru -&gt; Evict using approximated LRU, only keys with an expire set.# allkeys-lru -&gt; Evict any key using approximated LRU.# volatile-lfu -&gt; Evict using approximated LFU, only keys with an expire set.# allkeys-lfu -&gt; Evict any key using approximated LFU.# volatile-random -&gt; Remove a random key having an expire set.# allkeys-random -&gt; Remove a random key, any key.# volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)# noeviction -&gt; Don't evict anything, just return an error on write operations.## LRU means Least Recently Used# LFU means Least Frequently Used## Both LRU, LFU and volatile-ttl are implemented using approximated# randomized algorithms.## Note: with any of the above policies, Redis will return an error on write# operations, when there are no suitable keys for eviction.## At the date of writing these commands are: set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## The default is:## maxmemory-policy noeviction","link":"/2025/04/13/Redis%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/"},{"title":"windows命令","text":"记录windows相关命令 修改权限123# 示例代码：更改Windows文件夹所有权takeown /f E:\\project\\UC-BMS /r /d yicacls E:\\project\\UC-BMS /grant USERNAME:F /t 注：针对一下错误 12345.deploy_git' is owned by: (inconvertible) (S-1-5-21-463249815-3065990979-1447414722-1001)but the current user is: DESKTOP-SCA7ER8/username (S-1-5-21-1598257996-2487661147-1189533222-1001)To add an exception for this directory, call: takeown命令 1takeown [/s &lt;computer&gt; [/u [&lt;domain&gt;\\]&lt;username&gt; [/p [&lt;password&gt;]]]] /f &lt;filename&gt; [/a] [/r [/d {Y|N}]] 参数解析 参数 描述 /s &lt;computer&gt; 指定远程计算机的名称或 IP 地址（不使用反斜杠）。 默认值为本地计算机。 此参数适用于命令中指定的所有文件和文件夹。 /u [&lt;domain&gt;\\]&lt;username&gt; 使用指定用户帐户的权限运行脚本。 默认值为系统权限。 /p [&lt;[password&gt;] 指定在 /u 参数中指定的用户帐户的密码。 /f &lt;filename&gt; 指定文件名或目录名称模式。 指定模式时，可以使用通配符 *。 还可以使用语法 &lt;sharename&gt;\\&lt;filename&gt;。 /a 为管理员组而不是当前用户提供所有权。 如果未指定此选项，则会向当前登录到计算机的用户提供文件所有权。 /r 对指定目录和子目录中的所有文件执行递归作。 /d {Y|N} 禁止在当前用户对指定目录具有 列表文件夹 权限时显示的确认提示，而是使用指定的默认值。 /d 选项的有效值为：Y - 获取目录的所有权 N - 跳过目录注释：必须和/r结合使用 /? 获取帮助 icacls命令 详见：https://learn.microsoft.com/zh-cn/windows-server/administration/windows-commands/icacls 消除快捷键头将以下指令复制到txt文件，重命名bat结尾的文件，右键管理员运行 123456reg add &quot;HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Icons&quot; /v 29 /d &quot;%systemroot%\\system32\\imageres.dll,197&quot; /t reg_sz /ftaskkill /f /im explorer.exeattrib -s -r -h &quot;%userprofile%\\AppData\\Local\\iconcache.db&quot;del &quot;%userprofile%\\AppData\\Local\\iconcache.db&quot; /f /qstart explorerpause","link":"/2025/04/13/windows%E5%91%BD%E4%BB%A4/"},{"title":"Spring Bean作用域","text":"在Spring框架中，Bean的作用域（Spring Bean Scope）是一个核心概念，它决定了在Spring IoC容器中Bean实例的生命周期和可见性。Spring提供了多种作用域，包括singleton（单例）、prototype（原型）、request（请求）、session（会话）、application（应用程序）和websocket（WebSocket），每种作用域都适用于不同的应用场景。 Singleton作用域 Singleton作用域是Spring的默认作用域，它确保在Spring IoC容器中，每个Bean定义只有一个实例。无论请求多少次，都会返回同一个Bean实例。这种作用域适用于无状态的Bean，例如服务层、数据访问层或工具类。 Prototype作用域 与Singleton不同，Prototype作用域会为每个Bean请求创建一个新实例。这意味着每次调用*getBean()*时，都会得到一个新的Bean对象。这适用于那些有状态的Bean，其状态信息不应该被多个请求或线程共享。 Request、Session和Application作用域 这三个作用域都是基于Web应用的，它们分别将Bean的生命周期绑定到HTTP请求、用户会话和整个Web应用程序的生命周期。 Request作用域的Bean会为每个HTTP请求创建一个新实例， Application作用域的Bean则在整个ServletContext中只创建一个实例，适用于全局共享的数据。 Session作用域的Bean则在同一个HTTP会话中共享一个实例。 自定义作用域 Spring还允许开发者定义自己的作用域，通过实现Scope接口并注册到Spring容器中，可以创建满足特定需求的自定义作用域。 使用注解定义Bean的作用域 除了在XML配置文件中声明Bean的作用域，Spring还提供了注解方式来定义作用域。例如，使用*@Scope(“prototype”)注解可以将Bean声明为Prototype作用域，而@RequestScope、@SessionScope和@ApplicationScope*注解则分别用于声明对应的Web相关作用域。 作用域的选择 选择正确的Bean作用域对于管理应用程序的状态和资源非常重要。例如，对于需要跨多个请求保持状态的组件，应选择Request或Session作用域。对于全局配置或缓存信息，Application作用域可能更合适。而对于那些每次使用时都需要独立状态的组件，则应选择Prototype作用域。 在实际开发中，理解和选择合适的Spring Bean作用域对于构建高效、可维护的Spring应用至关重要。开发者应根据应用程序的具体需求和行为来选择最合适的作用域，以确保资源的有效管理和应用程序的稳定运行。","link":"/2025/04/16/Spring%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F/"},{"title":"算法—通过投票对团队排名","text":"现在有一个特殊的排名系统，依据参赛团队在投票人心中的次序进行排名，每个投票者都需要按从高到低的顺序对参与排名的所有团队进行排位。 排名规则如下： 参赛团队的排名次序依照其所获「排位第一」的票的多少决定。如果存在多个团队并列的情况，将继续考虑其「排位第二」的票的数量。以此类推，直到不再存在并列的情况。 如果在考虑完所有投票情况后仍然出现并列现象，则根据团队字母的字母顺序进行排名。 给你一个字符串数组 votes 代表全体投票者给出的排位情况，请你根据上述排名规则对所有参赛团队进行排名。 请你返回能表示按排名系统 排序后 的所有团队排名的字符串。 示例 1： 1234567输入：votes = [&quot;ABC&quot;,&quot;ACB&quot;,&quot;ABC&quot;,&quot;ACB&quot;,&quot;ACB&quot;]输出：&quot;ACB&quot;解释：A 队获得五票「排位第一」，没有其他队获得「排位第一」，所以 A 队排名第一。B 队获得两票「排位第二」，三票「排位第三」。C 队获得三票「排位第二」，两票「排位第三」。由于 C 队「排位第二」的票数较多，所以 C 队排第二，B 队排第三。 算法题位置： 1366. 通过投票对团队排名 - 力扣（LeetCode） 解答 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution { // 创建一个类用来对比 static class Ticket implements Comparable&lt;Ticket&gt; { char c; int[] ticket; public Ticket(char c, int[] ticket) { this.c = c; this.ticket = ticket; } @Override public int compareTo(Ticket o) { int compare = Arrays.compare(o.ticket, this.ticket); return compare != 0 ? compare : this.c - o.c; } } public String rankTeams(String[] votes) { if (votes.length == 0) { return &quot;&quot;; } if (votes.length == 1) { return votes[0]; } // 存储对应位置 Map&lt;Character, Ticket&gt; ticketMap = new HashMap&lt;&gt;(); int length = votes[0].length(); for (String vote : votes) { char[] array = vote.toCharArray(); for (int i = 0; i &lt; array.length; i++) { Ticket ticket = ticketMap.getOrDefault(array[i], new Ticket(array[i], new int[length])); ticket.ticket[i] += 1; ticketMap.put(array[i], ticket); } } TreeSet&lt;Ticket&gt; tickets = new TreeSet&lt;&gt;(ticketMap.values()); StringBuilder res = new StringBuilder(); for (Ticket ticket : tickets) { res.append(ticket.c); } return res.toString(); }}","link":"/2025/04/18/%E7%AE%97%E6%B3%95%E2%80%94%E9%80%9A%E8%BF%87%E6%8A%95%E7%A5%A8%E5%AF%B9%E5%9B%A2%E9%98%9F%E6%8E%92%E5%90%8D/"},{"title":"算法—二叉搜索子树的最大键值和","text":"给你一棵以 root 为根的 二叉树 ，请你返回 任意 二叉搜索子树的最大键值和。 二叉搜索树的定义如下： 任意节点的左子树中的键值都 小于 此节点的键值。 任意节点的右子树中的键值都 大于 此节点的键值。 任意节点的左子树和右子树都是二叉搜索树。 算法题位置： 1373. 二叉搜索子树的最大键值和 - 力扣（LeetCode） 解答： 首先要先判断出是否是二叉搜索树，因为题目给的一个二叉树 然后递归计算结果，取最大值 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667class TreeNode { int val; TreeNode left; TreeNode right; TreeNode() { } TreeNode(int val) { this.val = val; } TreeNode(int val, TreeNode left, TreeNode right) { this.val = val; this.left = left; this.right = right; }}public class Solution { private int res = 0; static class SubTree { // 判断是否是搜索二叉树 boolean isBST; // 树的最小值 int minValue; // 树的最大值 int maxValue; // 该树的总和 int sumValue; public SubTree(boolean isBST, int minValue, int maxValue, int sumValue) { this.isBST = isBST; this.minValue = minValue; this.maxValue = maxValue; this.sumValue = sumValue; } } public int maxSumBST(TreeNode root) { res = 0; dfs(root); return 0; } public SubTree dfs(TreeNode root) { if (root == null) { int INF = Integer.MAX_VALUE; return new SubTree(true, INF, -INF, 0); } // 获取左树结果 SubTree left = dfs(root.left); // 获取右树结果 SubTree right = dfs(root.right); // 判断是搜索二叉树的两个条件 if (left.isBST &amp;&amp; right.isBST &amp;&amp; root.val &gt; left.maxValue &amp;&amp; root.val &lt; right.minValue) { int sum = root.val + left.sumValue + right.sumValue; res = Math.max(res, sum); return new SubTree(true, Math.min(left.minValue, root.val), Math.max(right.maxValue, root.val), sum); } else { return new SubTree(false, 0, 0, 0); } }}","link":"/2025/04/18/%E7%AE%97%E6%B3%95%E2%80%94%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E5%AD%90%E6%A0%91%E7%9A%84%E6%9C%80%E5%A4%A7%E9%94%AE%E5%80%BC%E5%92%8C/"},{"title":"算法—不同路径","text":"一个机器人位于一个 m x n 网格的左上角 （0，0）。 机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（m-1,n-1）。 问总共有多少条不同的路径？ 62. 不同路径 - 力扣（LeetCode） 解答： 动态规划问题，先组建二维数组 因为只能向下或者向右移动一步，所以第一行和第一列路径其实都只有一条则为1 每个格子的路径条数，都是左边的条数加上正上方的条数和 12345678910111213141516class Solution { public int uniquePaths(int m, int n) { // 新建一个二维数组 int[][] arr = new int[m][n]; // 将数组每个元素都赋值为1 for (int i = 0; i &lt; m; i++) { Arrays.fill(arr[i], 1); } for (int i = 1; i &lt; m; i++) { for (int j = 1; j &lt; n; j++) { arr[i][j] = arr[i - 1][j] + arr[i][j - 1]; } } return arr[m-1][n-1]; }}","link":"/2025/04/21/%E7%AE%97%E6%B3%95%E2%80%94%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84/"},{"title":"Spring事务相关","text":"事务是逻辑上的一组操作，要么都执行，要么都不执行。 事务特性 原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 注：只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的。 需要格外注意的是：事务能否生效数据库引擎是否支持事务是关键。比如常用的 MySQL 数据库默认使用支持事务的 innodb引擎。但是，如果把数据库引擎变为 myisam，那么程序也就不再支持事务了！ Spring事务的种类Spring支持编程式事务和声明式事务管理两种方式 编程式事务 TransactionTemplate 12345678910111213141516@Resourceprivate TransactionTemplate transactionTemplate;public void testTransactionTemplate() { transactionTemplate.execute(new TransactionCallbackWithoutResult() { @Override protected void doInTransactionWithoutResult(TransactionStatus status) { try { // 代码 } catch (Exception e){ // 回滚 status.setRollbackOnly(); } } });} TransactionManager 123456789101112@Resourceprivate PlatformTransactionManager transactionManager;public void testTransactionManager() { TransactionStatus status = transactionManager.getTransaction(new efaultTransactionDefinition()); try { // 业务代码 transactionManager.commit(status); }catch (Exception e) { // 回滚 transactionManager.rollback(status); }} 注：代码侵入性强 声明式事务 @Transactional 该事务是建⽴在 AOP 之上的。其本质是通过 AOP 功能，对⽅法前后进⾏拦截，将事务处理的功能编织到拦截的⽅法中，也就是在⽬标⽅法开始之前启动⼀个事务，在执⾏完⽬标⽅法之后根据执⾏情况提交或者回滚事务 声明式事务失效的情况： 应用在非public修饰的方法上 propagation属性设置错误 TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常。 rollbackFor设置错误 两个方法都在同一个类中，调用会失效 抛出的异常被try catch处理了，也会失效 123456789101112131415161718192021222324252627282930313233343536373839@Target({ElementType.TYPE, ElementType.METHOD})@Retention(RetentionPolicy.RUNTIME)@Inherited@Documented@Reflectivepublic @interface Transactional { @AliasFor(&quot;transactionManager&quot;) String value() default &quot;&quot;; @AliasFor(&quot;value&quot;) String transactionManager() default &quot;&quot;; String[] label() default {}; // 事务传播行为 Propagation propagation() default Propagation.REQUIRED; // 事务的隔离级别 Isolation isolation() default Isolation.DEFAULT; // 事务超时时间，默认-1，如果超过该设置时间还没有完成，则自动回滚事务 int timeout() default TransactionDefinition.TIMEOUT_DEFAULT; String timeoutString() default &quot;&quot;; // 指定事务是否为只读事务 boolean readOnly() default false; // 触发事务回滚的异常类型，可以指定多个异常类型 Class&lt;? extends Throwable&gt;[] rollbackFor() default {}; String[] rollbackForClassName() default {}; Class&lt;? extends Throwable&gt;[] noRollbackFor() default {}; String[] noRollbackForClassName() default {};} Spring事务隔离级别 TransactionDefinition.ISOLATION_DEFAULT 使用后端数据库默认的隔离级别，MySQL 默认采用的 REPEATABLE_READ 隔离级别 Oracle 默认采用的 READ_COMMITTED 隔离级别. TransactionDefinition.ISOLATION_READ_UNCOMMITTED 最低的隔离级别，使用这个隔离级别很少，因为它允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读 TransactionDefinition.ISOLATION_READ_COMMITTED 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生 TransactionDefinition.ISOLATION_REPEATABLE_READ 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 TransactionDefinition.ISOLATION_SERIALIZABLE 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 Spring事务传播行为 TransactionDefinition.PROPAGATION_REQUIRED @Transactional注解默认使用，如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。如果外部方法开启事务并且被Propagation.REQUIRED的话，所有Propagation.REQUIRED修饰的内部方法和外部方法均属于同一事务 ，只要一个方法回滚，整个事务均回滚。 TransactionDefinition.PROPAGATION_REQUIRES_NEW ​ 创建一个新的事务，如果当前存在事务，则把当前事务挂起。也就是说不管外部方法是否开启事务，Propagation.REQUIRES_NEW修饰的内部方法会新开启自己的事务，且开启的事务相互独立，互不干扰。 TransactionDefinition.PROPAGATION_NESTED 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务执行； 如果当前没有事务，就执行与TransactionDefinition.PROPAGATION_REQUIRED类似的操作； TransactionDefinition.PROPAGATION_NESTED代表的嵌套事务以父子关系呈现，其核心理念是子事务不会独立提交，依赖于父事务，在父事务中运行；当父事务提交时，子事务也会随着提交，理所当然的，当父事务回滚时，子事务也会回滚； 子事务也有自己的特性，可以独立进行回滚，不会引发父事务的回滚，但是前提是需要处理子事务的异常，避免异常被父事务感知导致外部事务回滚； TransactionDefinition.PROPAGATION_MANDATORY 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性） 若是错误的配置以下 3 种事务传播行为，事务将不会发生回滚 TransactionDefinition.PROPAGATION_SUPPORTS: 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED: 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER: 以非事务方式运行，如果当前存在事务，则抛出异常。","link":"/2025/04/22/Spring%E4%BA%8B%E5%8A%A1%E7%9B%B8%E5%85%B3/"},{"title":"postgreSQL学习文档","text":"该文档用于学习PostgreSQL基础命令相关 1.创建数据库 CREATE DATABASE 命令需要在 PostgreSQL 命令窗口来执行 1CREATE DATABASE dbname; createdb 创建一个 PostgreSQL 数据库 1234567891011121314151617181920212223242526272829使用方法: createdb [选项]... [数据库名称] [描述]选项: -D, --tablespace=TABLESPACE 数据库默认表空间 -e, --echo 显示发送到服务端的命令 -E, --encoding=ENCODING 数据库编码 -l, --locale=LOCALE 数据库的本地化设置 --lc-collate=LOCALE 数据库的LC_COLLATE设置 --lc-ctype=LOCALE 数据库的LC_CTYPE设置 --icu-locale=LOCALE ICU locale setting for the database --icu-rules=RULES ICU rules setting for the database --locale-provider={libc|icu} locale provider for the database's default collation -O, --owner=OWNER 新数据库的所属用户 -S, --strategy=STRATEGY database creation strategy wal_log or file_copy -T, --template=TEMPLATE 要拷贝的数据库模板 -V, --version 输出版本信息, 然后退出 -?, --help 显示此帮助, 然后退出联接选项: -h, --host=HOSTNAME 数据库服务器所在机器的主机名或套接字目录 -p, --port=PORT 数据库服务器端口号 -U, --username=USERNAME 联接的用户名 -w, --no-password 永远不提示输入口令 -W, --password 强制提示输入口令 --maintenance-db=DBNAME 更改维护数据库默认情况下, 以当前用户的用户名创建数据库. 2.删除数据库 DROP DATABASE 删除数据库 123# DROP DATABASE 会删除数据库的系统目录项并且删除包含数据的文件目录。# DROP DATABASE 只能由超级管理员或数据库拥有者执行。DROP DATABASE [ IF EXISTS ] dbname dropdb 删除一个 PostgreSQL 数据库 123456789101112131415161718使用方法: dropdb [选项]... 数据库名选项: -e, --echo 显示发送到服务端的命令 -f, --force 强尝试在删除之前终止其他连接 -i, --interactive 删除任何东西之前给予提示 -V, --version 输出版本信息, 然后退出 --if-exists 如果数据库不存在则不报告错误 -?, --help 显示此帮助, 然后退出联接选项: -h, --host=HOSTNAM 数据库服务器所在机器的主机名或套接字目录 -p, --port=PORT 数据库服务器端口号 -U, --username=USERNAME 联接的用户名 -w, --no-password 永远不提示输入口令 -W, --password 强制提示输入口令 --maintenance-db=DBNAME 更改维护数据库 3.创建表格12345678CREATE TABLE table_name( column1 datatype, column2 datatype, column3 datatype, ..... columnN datatype, PRIMARY KEY( 一个或多个列 )); 4.删除表格1DROP TABLE table_name;","link":"/2025/05/18/postgreSQL%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/"},{"title":"windows11 消除快捷键图标","text":"消除windows11桌面快捷方式 去除箭头1.新建一个文本文件（如不显示.txt后缀电脑要在文件夹里设置“显示已知文件扩展名”） 2.复制下面代码粘贴后保存 123456reg add &quot;HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Icons&quot; /v 29 /d &quot;%systemroot%\\system32\\imageres.dll,197&quot; /t reg_sz /ftaskkill /f /im explorer.exeattrib -s -r -h &quot;%userprofile%\\AppData\\Local\\iconcache.db&quot;del &quot;%userprofile%\\AppData\\Local\\iconcache.db&quot; /f /qstart explorerpause 3.修改扩展名为 *.bat* 文件 4.右键以管理员身份打开 恢复箭头1234reg delete &quot;HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Icons&quot; /v 29 /ftaskkill /f /im explorer.exestart explorerpause","link":"/2025/10/12/windows11-%E6%B6%88%E9%99%A4%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%9B%BE%E6%A0%87/"},{"title":"mtr命令","text":"mtr命令是一个网络诊断工具，用于检测网络的连通性和延迟。MTR是My Traceroute的缩写，是traceroute和ping命令的结合体。 12345678910111213141516171819202122Usage: mtr [options] hostname -F, --filename FILE 从文件中读取hostname(s) -4 使用IPv4 -6 使用IPv6 -f, --first-ttl NUMBER 起跳ttl参数，跳过前面的N-1跳，只只显示TTL=N后的跳（不改变真实路由，只是不显示） -m, --max-ttl NUMBER maximum number of hops -u, --udp 使用UDP 替代 ICMP echo -T, --tcp 使用 TCP 替代ICMP echo -P, --port PORT 使用TCP、SCTP或UDP探测时的目标端口 -s, --psize PACKETSIZE 设置探测包的 payload 大小（字节） -i, --interval SECONDS 设置探测包的 发送间隔 -r, --report 报告模式（一次性输出，不刷新） -w, --report-wide 报告模式，宽屏对齐输出（字段不截断） -c, --report-cycles COUNT 发送探测包次数，设置20快速判断，设置100较为可信 -j, --json 以json格式输出 -x, --xml 以xml格式输出 -C, --csv 以csv格式输出 -l, --raw 以原始格式输出 -n, --no-dns 不做反向dns解析(只显示ip) -y, --ipinfo NUMBER 输出 IP 归属信息（国家 / 运营商） mtr 使用示例基础用法：诊断到目标主机的网络路径 1mtr www.baidu.com 执行后会显示一个实时更新的界面，包含以下信息： 跳数（Hop） 主机名或IP地址 丢包率（Loss%） 最近延迟（Last） 平均延迟（Avg） 最佳延迟（Best） 最差延迟（Wrst） 标准差（StDev）","link":"/2026/01/17/mtr%E5%91%BD%E4%BB%A4/"}],"tags":[{"name":"物联网","slug":"物联网","link":"/tags/%E7%89%A9%E8%81%94%E7%BD%91/"},{"name":"中间件","slug":"中间件","link":"/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"Java基础","slug":"Java基础","link":"/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"树","slug":"树","link":"/tags/%E6%A0%91/"},{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"PostgreSQL","slug":"PostgreSQL","link":"/tags/PostgreSQL/"},{"name":"命令大全","slug":"命令大全","link":"/tags/%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/"}],"categories":[{"name":"中间件","slug":"中间件","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"pages":[]}